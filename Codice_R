library( car )
library( ellipse )
library( faraway )
library( leaps )
library(MASS)
library( GGally)
library(BAS)
library( Matrix )
library(rgl)
library(corrplot)
library(RColorBrewer)
library(readr)
library(RColorBrewer)
library(stats)

dataset_anova=dataset
dataset_anova_2=dataset
dataset_poli=subset(dataset,dataset$X2025.Rank==111)
dataset=subset(dataset,dataset$X2025.Rank!=111)
n=nrow(dataset)
n #587
names(dataset)
summary(dataset) #ci sono tanti NA
sum(is.na(dataset))
dataset=na.omit(dataset)
sum(is.na(dataset))
summary(dataset)

dataset=subset(dataset, select = -X2024.Rank)
dataset=subset(dataset, select = -Employer.Reputation)
dataset=subset(dataset, select = -International.Faculty)
dataset=subset(dataset, select = -International.Research.Network)


ggpairs(dataset[,c('QS.Overall.Score','Size','Academic.Reputation','Faculty.Student','Citations.per.Faculty','International.Students','Employment.Outcomes','Sustainability')])
modello_nullo = lm( QS.Overall.Score ~ 1, data = dataset )
summary(modello_nullo)
modello_completo = lm(QS.Overall.Score ~ Academic.Reputation + Faculty.Student + Citations.per.Faculty + International.Students + Employment.Outcomes + Sustainability, data = dataset)
summary(modello_completo)
AIC(modello_completo)

step(modello_completo, direction="both",trace=T)


vif(modello_completo)


x=model.matrix(modello_completo)[ , -1]
y=dataset$QS.Overall.Score
adjr=leaps(x,y,method="adjr2")
adjr

bestmodel_adjr2_ind = which.max( adjr$adjr2 )
adjr$which[ bestmodel_adjr2_ind, ] 
maxadjr( adjr, 5 ) #prendiamo quello più semplice 1,2,3,4

g = lm(QS.Overall.Score ~ Academic.Reputation + Faculty.Student + Citations.per.Faculty + International.Students, data = dataset)
summary(g)
vif(g)
ggpairs(dataset[,c('Academic.Reputation','Faculty.Student','Citations.per.Faculty','International.Students')])
AIC(g)

#validità modello: vediamo se ora i residui sono normali

#errori normali
qqnorm(g$res)
qqline(g$res)

#shapiro test
shapiro.test(g$res) #p-value basso
hist(g$res)
boxplot(g$res)

#omoschedasticità
plot(g$fit,g$res) #sono in media attorno allo zero e che aumentano, proviamo ad individuare i punti influenti
plot(g,which=1)


b=boxcox(g, data = dataset)
best_lambda_ind=which.max(b$y)
best_lambda=b$x[best_lambda_ind]
best_lambda



#analisi punti influenti

#leverages
p=g$rank #p=5
n=dim(dataset)[1] #n=587
lev=hatvalues(g)
plot(g$fitted.values,lev)
abline(h=2*(p/n))
watchout_points_lev=lev[which(lev>2*(p/n))]
watchout_ids_lev=seq_along(lev)[which(lev>2*p/n)]


#residui standardizzati
gs=summary(g)
res_std=g$res/gs$sigma
plot(g$fitted.values,res_std)
abline(h=c(-2,2))
watchout_ids_rstd = which( abs( res_std ) > 2 )
watchout_rstd = res_std[ watchout_ids_rstd ]
watchout_rstd

#residui studentizzati
stud=rstandard(g)
plot(g$fitted.values,stud)
abline(h=c(-2,2))
watchout_ids_stud = which( abs( stud ) > 2 )
watchout_stud = stud[ watchout_ids_stud ]
watchout_stud



g_post_lev=lm( QS.Overall.Score ~ Academic.Reputation + Faculty.Student + Citations.per.Faculty + International.Students , data=dataset, subset = ( lev<2*p/n))
summary(g_post_lev)
AIC(g_post_lev)

#validità modello: vediamo se ora i residui sono normali

#errori normali
qqnorm(g_post_lev$res)
qqline(g_post_lev$res)

#shapiro test
shapiro.test(g_post_lev$res) #p-value basso
hist(g_post_lev$res)
boxplot(g_post_lev$res)

#omoschedasticità
plot(g_post_lev$fit,g_post_lev$res) #sono in media attorno allo zero e che aumentano, proviamo ad individuare i punti influenti
plot(g_post_lev,which=1)


g_post_rs=lm( QS.Overall.Score ~ Academic.Reputation + Faculty.Student + Citations.per.Faculty + International.Students, data=dataset, subset = ( abs(stud)<2 ) )
summary(g_post_rs)
AIC(g_post_rs) #si abbassa ma perdiamo noramlità

#validità modello: vediamo se ora i residui sono normali

#errori normali
qqnorm(g_post_rs$res)
qqline(g_post_rs$res)


#shapiro test
shapiro.test(g_post_rs$res)
hist(g_post_rs$res)
boxplot(g_post_rs$res)



g_post_both=lm( QS.Overall.Score ~ Academic.Reputation + Faculty.Student + Citations.per.Faculty + International.Students , data=dataset, subset = ( abs(stud)<2 | lev<2*p/n ))
summary(g_post_both)
AIC(g_post_both)

#validità modello: vediamo se ora i residui sono normali

#errori normali
qqnorm(g_post_both$res)
qqline(g_post_both$res)


#shapiro test
shapiro.test(g_post_both$res)
hist(g_post_both$res)
boxplot(g_post_both$res)



summary(g_post_both)


#Predizione

#Stima puntuale di y_hat
y_predict=predict(g_post_both,dataset_poli)
y_predict
y_mano=g_post_both$coefficients[1]+g_post_both$coefficients[2]*dataset_poli$Academic.Reputation+g_post_both$coefficients[3]*dataset_poli$Faculty.Student+g_post_both$coefficients[4]*dataset_poli$Citations.per.Faculty+g_post_both$coefficients[5]*dataset_poli$International.Students
y_mano

#Intervallo di confidenza per y_hat
y_confidence=predict(g_post_both,dataset_poli,interval='prediction',se=T)
y_confidence


#Intervallo di confidenza per E[y_hat]
y_confidence_E=predict(g_post_both,dataset_poli,interval='confidence',se=T)
y_confidence_E



#ANOVA su US, UK, FR, DE, IT n=5
names(dataset_anova)
dataset_anova=subset(dataset_anova,select=c(QS.Overall.Score,Location))
dataset_anova=subset(dataset_anova,dataset_anova$Location %in% c('US','UK','FR','DE','IT'))
summary(dataset_anova)
my_colors=brewer.pal(5,'Set2')
boxplot( QS.Overall.Score ~ Location, data=dataset_anova, col = my_colors)

#Ipotesi ANOVA

#Normalità dei gruppi
Ps = tapply( dataset_anova$QS.Overall.Score,dataset_anova$Location , function( x ) ( shapiro.test( x )$p ) )
Ps


dataset_IT=subset(dataset_anova,dataset_anova$Location=='IT')
shapiro.test(dataset_IT$QS.Overall.Score)

reg=lm(QS.Overall.Score~Location,data=dataset_anova)
anB=boxcox(reg,lambda = seq(-3,3,by=0.01))
best_lambda=anB$x[which.max(anB$y)]
best_lambda


Ps = tapply( (dataset_anova$QS.Overall.Score ^ best_lambda - 1)/best_lambda,dataset_anova$Location , function( x ) ( shapiro.test( x )$p ) )
Ps

boxplot( (QS.Overall.Score ^ best_lambda - 1)/best_lambda ~ Location, data=dataset_anova, col = my_colors)


#Omoschedasticità

leveneTest( (dataset_anova$QS.Overall.Score ^ best_lambda - 1)/best_lambda ,dataset_anova$Location )
bartlett.test(  (dataset_anova$QS.Overall.Score ^ best_lambda - 1)/best_lambda ,dataset_anova$Location )


mod = lm( QS.Overall.Score ~ Location , data=dataset_anova)
summary( mod )
anova( mod )



#ANOVA su UK, FR, DE, IT n=4
names(dataset_anova)
dataset_anova=subset(dataset_anova,dataset_anova$Location %in% c('UK','FR','DE','IT'))
summary(dataset_anova)
my_colors=brewer.pal(4,'Set2')
boxplot( QS.Overall.Score ~ Location, data=dataset_anova, col = my_colors)

#Ipotesi ANOVA

#Normalità dei gruppi
Ps = tapply( dataset_anova$QS.Overall.Score,dataset_anova$Location , function( x ) ( shapiro.test( x )$p ) )
Ps


dataset_IT=subset(dataset_anova,dataset_anova$Location=='IT')
shapiro.test(dataset_IT$QS.Overall.Score)

reg=lm(QS.Overall.Score~Location,data=dataset_anova)
anB=boxcox(reg,lambda = seq(-3,3,by=0.01))
best_lambda=anB$x[which.max(anB$y)]
best_lambda


Ps = tapply( (dataset_anova$QS.Overall.Score ^ best_lambda - 1)/best_lambda,dataset_anova$Location , function( x ) ( shapiro.test( x )$p ) )
Ps

boxplot( (QS.Overall.Score ^ best_lambda - 1)/best_lambda ~ Location, data=dataset_anova, col = my_colors)


#Omoschedasticità

leveneTest( (dataset_anova$QS.Overall.Score ^ best_lambda - 1)/best_lambda ,dataset_anova$Location )
bartlett.test(  (dataset_anova$QS.Overall.Score ^ best_lambda - 1)/best_lambda ,dataset_anova$Location )


mod = lm( QS.Overall.Score ~ Location , data=dataset_anova)
summary( mod )
anova( mod )



#ANOVA su US IT n=2
#attento a rifare il dataset anova
names(dataset_anova_2)
dataset_anova_2=subset(dataset_anova_2,select=c(QS.Overall.Score,Location))
dataset_anova_2=subset(dataset_anova_2,dataset_anova_2$Location %in% c('US','IT'))
summary(dataset_anova_2)
my_colors=brewer.pal(2,'Set2')
boxplot( QS.Overall.Score ~ Location, data=dataset_anova_2, col = my_colors)

#Ipotesi ANOVA

#Normalità dei gruppi
Ps = tapply( dataset_anova_2$QS.Overall.Score,dataset_anova_2$Location , function( x ) ( shapiro.test( x )$p ) )
Ps


dataset_IT=subset(dataset_anova_2,dataset_anova_2$Location=='IT')
shapiro.test(dataset_IT$QS.Overall.Score)

reg=lm(QS.Overall.Score~Location,data=dataset_anova_2)
anB=boxcox(reg,lambda = seq(-3,3,by=0.01))
best_lambda=anB$x[which.max(anB$y)]
best_lambda


Ps = tapply( (dataset_anova_2$QS.Overall.Score ^ best_lambda - 1)/best_lambda,dataset_anova_2$Location , function( x ) ( shapiro.test( x )$p ) )
Ps

boxplot( (QS.Overall.Score ^ best_lambda - 1)/best_lambda ~ Location, data=dataset_anova_2, col = my_colors)


#Omoschedasticità

leveneTest( (dataset_anova_2$QS.Overall.Score ^ best_lambda - 1)/best_lambda ,dataset_anova_2$Location )
bartlett.test(  (dataset_anova_2$QS.Overall.Score ^ best_lambda - 1)/best_lambda ,dataset_anova_2$Location )


mod = lm( QS.Overall.Score ~ Location , data=dataset_anova_2)
summary( mod )
anova( mod )
