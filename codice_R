library( car )
library( ellipse )
library( faraway )
library( leaps )
library(MASS)
library( GGally)
library(rgl)

#primo modello 6 covariate
ggpairs(dataset[,c('mpg','cylinders','displacement','weight','horsepower','acceleration','model.year')])
g1 = lm( mpg ~ cylinders + displacement + weight + horsepower + acceleration + model.year, data = dataset )
summary(g1)

#R2=0.8087 R2_adj=0.8058
#noto che quelle significative sono weight e model.year

#controllo correlazioni
vif(g1) #noto che alcune sono sopra la soglia di 5/10
cor(dataset$cylinders,dataset$displacement) #calcolo la correlazione tra queste 2, è alta quindi elimino il displacement

#secondo modello: levo accelerazione perchè dal ggpairs vedo che non influenza linearmente che non mi serve e displacement
g2=lm(mpg ~ cylinders + weight + horsepower + model.year, data = dataset)
summary(g2)

#R2=0.8079 R2_adj=0.806


#terzo modello: noto che cylinders non ha impatto, la levo
g3=lm(mpg ~ weight + horsepower + model.year, data = dataset)
summary(g3)

#R2=0.8079 R2_adj=0.8064

#quarto modello: noto che horsepower non ha impatto, la levo
g4=lm(mpg ~ weight + model.year, data = dataset)
summary(g4)

#R2=0.8079 R2_adj=0.8069

#vif sotto al 5 (buono)
vif(g4)



#validità modello

#errori normali
qqnorm(g4$res)
qqline(g4$res)

#notiamo che si discosta soproattuto sulle code, facciamo uno shapiro test per sicurezza

#shapiro test
shapiro.test(g4$res) #molto basso, quinndi rifiuto la normalità dei residui
hist(g4$res) #noto anomalia sulla coda destra
boxplot(g4$res) #noto anomalia sulla coda destra

#omoschedasticità
plot(g4$fit,g4$res)
plot(g4,which=1) #sono in media attorno allo zero e non osserviamo pattern strani, tipo aumento o diminuzione, possiamo fare meglio dopo eliminando i punti influenti



#boxcox: cerchiamo di trovare un lambda che ci permetta di avere residui normali
b=boxcox(mpg ~ weight + model.year, data = dataset)
best_lambda_ind=which.max(b$y)
best_lambda=b$x[best_lambda_ind]
best_lambda
g5=lm((mpg^best_lambda-1)/best_lambda ~ weight + model.year, data = dataset)
summary(g5)

#R2=0.8791 R2_adj=0.8785

#validità modello: vediamo se ora i residui sono normali

#errori normali
qqnorm(g5$res)
qqline(g5$res)

#ha ancora anomalia sulle code

#shapiro test
shapiro.test(g5$res)
hist(g5$res)
boxplot(g5$res)

#lo shapiro test ha ancora p-value basso

#omoschedasticità
plot(g5$fit,g5$res) #sono in media attorno allo zero e non osserviamo pattern strani, tipo aumento o diminuzione, possiamo fare meglio dopo eliminando i punti influenti
plot(g5,which=1)


#analisi punti influenti

#leverages
p=g5$rank #p=3
n=dim(dataset)[1] #n=398
lev=hatvalues(g5)
plot(g5$fitted.values,lev)
abline(h=2*(p/n))
watchout_points_lev=lev[which(lev>2*(p/n))]
watchout_ids_lev=seq_along(lev)[which(lev>2*p/n)]


#residui standardizzati
g5s=summary(g5)
res_std=g5$res/g5s$sigma
plot(g5$fitted.values,res_std)
abline(h=c(-2,2))
watchout_ids_rstd = which( abs( res_std ) > 2 )
watchout_rstd = res_std[ watchout_ids_rstd ]
watchout_rstd

#residui studentizzati
stud=rstandard(g5)
plot(g5$fitted.values,stud)
abline(h=c(-2,2))
watchout_ids_stud = which( abs( stud ) > 2 )
watchout_stud = stud[ watchout_ids_stud ]
watchout_stud

#errori standardizzati uguali a quelli studentizzati

#grafico che considera tutto
x11()
influencePlot(g5,id.method="identify",main="influential plot",sub="circle size is proportial to Cook's distance")



plot(g5,which=5)
